{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Rainfall Detection and Alerting System (ERDAS) v 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'OSE GIS'\n",
    "__project__ = 'Extreme Rainfall Detection and Alerting System (ERDAS)'\n",
    "__contact__ = 'michael.manalili@wfp.org', 'wfp.hq.gis@wfp.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Engine package initialized successfully..\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import requests, os, time, shutil\n",
    "from time import strptime\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import descartes\n",
    "import schedule\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart #python3\n",
    "from email.mime.base import MIMEBase #python3\n",
    "from email import encoders #python3\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import ee\n",
    "import eeconvert\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterstats import zonal_stats\n",
    "import cdsapi\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 \n",
    "import io\n",
    "from lxml import html\n",
    "import wget\n",
    "import cdsapi\n",
    "from configparser import ConfigParser\n",
    "import sentinelsat\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 \n",
    "import pandas.io.sql as psql\n",
    "from io import BytesIO as StringIO\n",
    "from osgeo import ogr\n",
    "from ftplib import FTP\n",
    "import pycountry\n",
    "import uuid\n",
    "#import pysftp\n",
    "#from io import BytesIO as StringIO\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print ('Earth Engine package initialized successfully..')\n",
    "except ee.EEException as e:\n",
    "    print ('Earth Engine package failed to initialize!')\n",
    "except:\n",
    "    print ('Unexpected error:', sys.exc_info()[0])\n",
    "    raise\n",
    "\n",
    "# from IPython.display import Image\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "#pd.set_option('mode.chained_assignment', 'raise')\n",
    "\n",
    "execTime = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import geopandas as gpd\n",
    "#dir(gpd.GeoDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.today()\n",
    "d = str(now)\n",
    "date = d[0:10]\n",
    "date_cut = date.replace('-', '')\n",
    "whitelist_data = 'extreme_precip_alert_' + date_cut\n",
    "alert_data = 'red_alert_' + date_cut\n",
    "\n",
    "script = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "root = os.path.dirname(script)\n",
    "\n",
    "# Assumed this folders are pre-created\n",
    "process_root = root + '/data/processing'\n",
    "process_amsr2 = process_root + '/process_amsr2/'\n",
    "process_cdsapi = process_root + '/process_cdsapi/'\n",
    "process_ecmwf = process_root + '/process_ecmwf/'\n",
    "process_pxr = process_root + '/process_pxr/'\n",
    "\n",
    "alert_csv_path = root + '/data/alert/'\n",
    "s1_txt_path = root + '/data/alert/'\n",
    "map_view_path = root + '/data/view/'\n",
    "\n",
    "alert_data_name = 'Extreme_rainfall_alert_beta_' + date_cut + '.csv'\n",
    "map_view_name = 'Map_view_' + date_cut + '.html'\n",
    "s1_name = 'sentinel_sched_' + date_cut + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config loaded.\n"
     ]
    }
   ],
   "source": [
    "config = ConfigParser()\n",
    "config.read(os.path.join(root, \"config.txt\"))\n",
    "\n",
    "esa_un = config.get('sentinelsat', 'ss_un')\n",
    "esa_pw = config.get('sentinelsat', 'ss_pw')\n",
    "esa_link = config.get('sentinelsat', 'ss_link')\n",
    "api = SentinelAPI(esa_un, esa_pw, esa_link)\n",
    "api\n",
    "\n",
    "config.read(os.path.join(root, \"config.txt\"))\n",
    "smtp_un = config.get('dbtrack','dbt_uname')\n",
    "smtp_pw = config.get('dbtrack','dbt_pword')\n",
    "print('config loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECMWF_SDI_raster_cat = config.get(\"ECMWF\",\"ECMWF_SDI_raster_cat\")\n",
    "#ECMWF_SDI_raster_cat = os.path.join(connfiles_folder,ECMWF_SDI_raster_cat)\n",
    "\n",
    "#ECMWF_SDI_mosaic_dataset= config.get(\"ECMWF\",\"ECMWF_SDI_mosaic_dataset\")\n",
    "#ECMWF_SDI_mosaic_dataset = os.path.join(connfiles_folder,ECMWF_SDI_mosaic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/Users/michael/GEO/FBF/PHL/data/\"\n",
    "d = data_root + \"Maguindanao_adm2.shp\"\n",
    "\n",
    "# maguindanao = gpd.read_file(d)\n",
    "# maguindanao.reset_index(inplace=True)\n",
    "# maguindanao = maguindanao.rename(columns = {'index':'UID'})\n",
    "# maguindanao.to_file(data_root + \"Maguindanao_UID.shp\")\n",
    "# l = list(maguindanao)\n",
    "# print(l)\n",
    "# alist_m.remove('UID')\n",
    "# l = alist_m\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/miniconda2/envs/adamf/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CC_2',\n",
       " 'ENGTYPE_2',\n",
       " 'GID_0',\n",
       " 'GID_1',\n",
       " 'GID_2',\n",
       " 'HASC_2',\n",
       " 'NAME_0',\n",
       " 'NAME_1',\n",
       " 'NAME_2',\n",
       " 'NL_NAME_1',\n",
       " 'NL_NAME_2',\n",
       " 'TYPE_2',\n",
       " 'VARNAME_2',\n",
       " 'geometry']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfp_adm0 = ee.FeatureCollection(\"projects/unwfp/HQGIS/fbf/Maguindanao_UID\")\n",
    "data = eeconvert.fcToGdf(wfp_adm0)\n",
    "l = list(data)\n",
    "l.remove('UID')\n",
    "l\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City/Municipality</th>\n",
       "      <th>Barangay</th>\n",
       "      <th>Poor Households</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BANGUED (Capital)</td>\n",
       "      <td>Agtangao</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BANGUED (Capital)</td>\n",
       "      <td>Angad</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANGUED (Capital)</td>\n",
       "      <td>Bañacao</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANGUED (Capital)</td>\n",
       "      <td>Bangbangar</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BANGUED (Capital)</td>\n",
       "      <td>Cabuloan</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City/Municipality    Barangay  Poor Households\n",
       "0  BANGUED (Capital)    Agtangao               96\n",
       "1  BANGUED (Capital)       Angad               60\n",
       "2  BANGUED (Capital)     Bañacao              108\n",
       "3  BANGUED (Capital)  Bangbangar               27\n",
       "4  BANGUED (Capital)    Cabuloan               29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_muni = pd.read_excel(data_root + \"listahanan_poorfam_brgy.xlsx\")\n",
    "poor_muni.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_red(ans, reducer, scale):\n",
    "    data = ans.reduceRegions(\n",
    "            collection = wfp_aoi,\n",
    "            reducer = reducer,\n",
    "            crs='EPSG:3857',\n",
    "            scale=scale,\n",
    "            tileScale=1)\n",
    "    return data   \n",
    "\n",
    "def write2file(filename, header, gdf):\n",
    "    data = gdf.to_csv(filename, columns=header, encoding='utf-8')\n",
    "    return data\n",
    "\n",
    "def export2drive_raster(raster, bbox ,prefix,scale):\n",
    "    run = ee.batch.Export.image.toDrive(\n",
    "         image=raster, \n",
    "         scale=scale,\n",
    "         fileNamePrefix = prefix,\n",
    "         region = ee.Feature(bbox).geometry().bounds().getInfo()['coordinates'], #can also be single country\n",
    "         maxPixels = 1e13,\n",
    "         fileFormat='GeoTiff',\n",
    "         cloudOptimized=True).start()\n",
    "    return run\n",
    "\n",
    "#Format Options: GeoJSON, SHP, KML\n",
    "def export2drive_table(ee_featCol, description):\n",
    "    table = ee.batch.Export.table.toDrive(\n",
    "         collection=ee_featCol, \n",
    "         description=description,\n",
    "         fileFormat='CSV')#.start() \n",
    "    return table\n",
    "\n",
    "def month(n):\n",
    "    start = ee.Date('2014-01-01').advance(n, 'month')\n",
    "    end = start.advance(1,'month')\n",
    "    return ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/operational').select('hourlyPrecipRate').filterDate(start,end).mean().set('system:time_start', start.millis())\n",
    "\n",
    "def get_wc():\n",
    "    #x = ee.Image(collectionList.get(band_month))\n",
    "    wc = ee.Image('users/wfphqgis/CLIM/wc20_30s_prec_'+s_bm)\n",
    "    wc_vector_mean = spatial_red(wc,ee.Reducer.mode(),900)\n",
    "    df_wc = eeconvert.fcToGdf(wc_vector_mean)\n",
    "    dff_wc = df_wc.drop(columns = l)\n",
    "    dff_wc_r = dff_wc.rename(columns={'mode':'WC_Mean_Prec'})\n",
    "    return dff_wc_r\n",
    "\n",
    "def get_sm2map():\n",
    "    #x = ee.Image(collectionList.get(band_month))\n",
    "    sm2 = ee.Image('users/wfphqgis/CLIM/clm_precipitation_sm2rain_m_1km_s00cm_20072018_v02_'+s_bm)\n",
    "    sm2_vector_mean = spatial_red(sm2,ee.Reducer.mode(),900)\n",
    "    df_sm2 = eeconvert.fcToGdf(sm2_vector_mean)\n",
    "    dff_sm2 = df_sm2.drop(columns = l)\n",
    "    dff_sm2_r = dff_sm2.rename(columns={'mode':'Mean_Prec'})\n",
    "    return dff_sm2_r\n",
    "\n",
    "def get_ecmwf():\n",
    "    data_ecmwf = ee.Image('users/wfphqgis/CLIM/ecmwf_reanalysis_ymonmeanR_ymonmean')\n",
    "    crs = data_ecmwf.projection().crs()\n",
    "    scale = 9000\n",
    "    tp = data_ecmwf.select('b' + s_bm)\n",
    "    ecmwf = tp.resample('bilinear').reproject(crs = crs, scale = scale)\n",
    "    wc_vector_mean = spatial_red(tp,ee.Reducer.mode(),9000)\n",
    "    df_wc = eeconvert.fcToGdf(wc_vector_mean)\n",
    "    dff_wc = df_wc.drop(columns = l)\n",
    "    dff_wc_r = dff_wc.rename(columns={'mode':'ECMWF_Mean_Prec'})\n",
    "    return dff_wc_r\n",
    "\n",
    "def get_amsr2():\n",
    "    #data = 'http://www.gdacs.org/flooddetection/DATA/AMSR2/AvgSignalTiffs/2019' 400K max\n",
    "    data = 'http://www.gdacs.org/flooddetection/DATA/AMSR2/MagTiffs/2019' #20K max\n",
    "    now = datetime.today()\n",
    "    d = str(now)\n",
    "    date = d[0:10]\n",
    "    date_frmt = date.replace('-', '')\n",
    "\n",
    "    page = requests.get(data)\n",
    "    webpage = html.fromstring(page.content)\n",
    "\n",
    "    amsr2 = webpage.xpath('//a/@href')\n",
    "    amsr2_last = amsr2[-1]\n",
    "    cur_year = d[0:4]\n",
    "    base = 'http://www.gdacs.org'\n",
    "    #prod = 'signal_4days_avg_4days_'\n",
    "    prod = 'mag_signal_'\n",
    "    hd5 = '_HD5'\n",
    "    ext = '.tif'\n",
    "    lnk =  base + amsr2_last + prod + date_frmt +hd5 +ext\n",
    "    dl = wget.download(lnk,process_amsr2)\n",
    "    return dl\n",
    "\n",
    "def get_s1_info(i):\n",
    "    s1 = api.query(final_df.envelope[i],\n",
    "                   date=sensing_date,\n",
    "                   platformname='Sentinel-1',\n",
    "                   producttype='GRD',\n",
    "                   area_relation='Intersects') #Intersects, IsWithin\n",
    "                   #orbitdirection='ASCENDING')\n",
    "    s1_json = api.to_geojson(s1)\n",
    "    s1_gdf = api.to_geodataframe(s1)\n",
    "    s1_gdf\n",
    "\n",
    "    s1_gdf = s1_gdf[['ingestiondate']]#,'beginposition','ingestiondate','platformname','orbitnumber', 'producttype', 'endposition']]\n",
    "    s1_gdf.sort_values('ingestiondate', ascending=True).head()\n",
    "    s1_gdf\n",
    "\n",
    "    dates = s1_gdf[\"ingestiondate\"].dt.date.values\n",
    "    map_date = dates + timedelta(days=11)\n",
    "    ld = len(dates)\n",
    "    \n",
    "    print_path = open(root + '/data/alert/' + 'sentinel_sched_' + date_cut + '.txt','a')\n",
    "    \n",
    "    p = print(\"Sentinel Acquisition Schedule: \" + \"{0}: {1} \\n{2} alert! \\nThere are {3} Sentinel-1 overpass \\nMappable on:\\n{4}\\n\"\n",
    "             .format(final_df['adm0_name'][i],final_df['adm2_name'][i],final_df['status'][i],ld,map_date),\n",
    "             file=print_path)\n",
    "    return p\n",
    "\n",
    "def job():\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = 'wfp.hq.dbtrack@gmail.com'\n",
    "    msg['Subject'] = \"Extreme Precipitation Alert\"\n",
    "    \n",
    "    body = \"\"\"<div style=\"color:rgb(28, 130, 196)\"><font size=\"+2\"><b><img id=\"myimage\" src=\"https://mw1.google.com/crisisresponse/icons/un-ocha/disaster_heavy_rain_100px_icon.png\"></img>\n",
    "    <br /> Extreme Precipitation Alert</b> </font></div>\n",
    "    <br/><b>Please See attached list and location of WFP country concerned.</b></b>\n",
    "    <br />\n",
    "    <br/> Number of <font color=\"YELLOW\">YELLOW</font> Alerts: %s\n",
    "    <br/> Number of <font color=\"ORANGE\">ORANGE</font> Alerts: %s\n",
    "    <br/> Number of <font color=\"RED\">RED</font> Alerts: %s\n",
    "    <br />\n",
    "    <br/><b>Note on color categories:</b></b>\n",
    "    <br />\n",
    "    <br/>Yellow: The 3-days accumulated rainfall is greater than the average 3 days maximum total precipitation (moderate nowcast)\n",
    "    <br/>Orange: The 3-days accumulated rainfall is greater than the long term mean rainfall for that month (high nowcast)\n",
    "    <br/>Red*: The 3-days accumulated rainfall + 3-days forecast is greater than the long term mean rainfall (high forecast)\n",
    "    <br/><i>*The red alert is valid until 3-5 days of forecast</i></b>\n",
    "    <br />\n",
    "    <br/><b>Emergency Mapping/Charter Activation Links:</b></b>\n",
    "    <br />\n",
    "    <br/><b>--------------------------------------------------------------------------------</b></b>\n",
    "    <br/>This is an automatically generated email, please do not reply.<br/>\n",
    "    <br/>Service provided by \n",
    "    <br/><i>UNITED NATIONS WORLD FOOD PROGRAMME\n",
    "    <br/>WFP Emergency Preparedness & Support Response Division\n",
    "    <br/>Contact: <a href=\"mailto:hq.gis@wfp.org\">HQ Geospatial Support Unit</a></i></p>\n",
    "    \"\"\" % (y,o,r) #add 'a' in the modulo\n",
    "\n",
    "    alert_fn = alert_csv_path + alert_data_name\n",
    "    mapview_fn = map_view_path + map_view_name\n",
    "    s1_fn = s1_txt_path + s1_name\n",
    "    \n",
    "    alerts = MIMEBase('application', \"octet-stream\")\n",
    "    mapview = MIMEBase('application', \"octet-stream\")\n",
    "    s1view = MIMEBase('application', \"octet-stream\")\n",
    "    \n",
    "    alerts.set_payload(open(alert_fn, \"rb\").read())\n",
    "    mapview.set_payload(open(mapview_fn, \"rb\").read())\n",
    "    s1view.set_payload(open(s1_fn, \"rb\").read())\n",
    "    \n",
    "    encoders.encode_base64(alerts)\n",
    "    encoders.encode_base64(mapview)\n",
    "    encoders.encode_base64(s1view)\n",
    "    \n",
    "    alerts.add_header('Content-Disposition', 'attachment; filename=%s'%alert_data_name)\n",
    "    mapview.add_header('Content-Disposition', 'attachment; filename=%s'%map_view_name)\n",
    "    s1view.add_header('Content-Disposition', 'attachment; filename=%s'%s1_name)\n",
    "    \n",
    "    msg.attach(alerts)\n",
    "    msg.attach(mapview)\n",
    "    msg.attach(s1view)\n",
    "    \n",
    "    msg.attach(MIMEText(body, 'html'))\n",
    "    \n",
    "#     s = smtplib.SMTP('smtp.gmail.com', 587) #Anywhere\n",
    "#     s.starttls() #Anywhere\n",
    "    \n",
    "    s = smtplib.SMTP_SSL('smtp.gmail.com', 465) # WFP domain\n",
    "    \n",
    "    s.ehlo()\n",
    "    s.login(smtp_un, smtp_pw)\n",
    "    sender = 'wfp.hq.dbtrack@gmail.com'\n",
    "    \n",
    "    #recipients = ['michaelandrew.manalili@gmail.com']#,'michael.manalili@wfp.org','abdel-lathif.younous@wfp.org','rohini.swaminathan@wfp.org']\n",
    "    recipients = ['rohini.swaminathan@wfp.org','sirio.modugno@wfp.org','stefano.cairo@wfp.org','michael.manalili@wfp.org','abdel-lathif.younous@wfp.org','michaelandrew.manalili@gmail.com']\n",
    "            \n",
    "    if gbl_alert.empty == True:\n",
    "        pass\n",
    "        print('DataFrame is Empty, skipping email broadcast...')\n",
    "        \n",
    "    else:\n",
    "        s.sendmail(sender, recipients, str(msg))\n",
    "        s.quit()\n",
    "        print('ALERT sent to subscribers!')\n",
    "\n",
    "#Flood: https://mw1.google.com/crisisresponse/icons/un-ocha/disaster_flood_100px_icon.png\n",
    "#http://www.gdacs.org/flooddetection/DATA/AMSR2/\n",
    "#http://www.gdacs.org/flooddetection/DATA/AMSR2/SignalTiffs/2019/\n",
    "#http://www.gdacs.org/flooddetection/DATA/AMSR2/MagTiffs/2019/\n",
    "\n",
    "# if mode == 'prod':\n",
    "#             mailServer = smtplib.SMTP(\"smtp.gmail.com\", 587)\n",
    "#         else:### in virtual machines security rules don't allow anymore using  (old version) TLS connection, but only SSL. In production, SSL version is good enough\n",
    "#             mailServer = smtplib.SMTP_SSL(\"smtp.gmail.com\", 465)\n",
    "\n",
    "### Add the below to the message to include GIS focal points\n",
    "# <br /><b>GIS Focal point for coordinating the event:</b>\n",
    "# <br />\n",
    "# </b>%s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_global = pd.read_csv(root + '/wfp' + '/wfp_country.csv', index_col=0)\n",
    "# iso_global_list = iso_global['ISO3'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add population to:\n",
    "#Forecast + XDAYS + Population (Abdel to advise on this number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBL_adm0 = ee.FeatureCollection(\"users/wfphqgis/BND/wfp_bnd_inform2019\") #iso3\n",
    "#GBL_adm2 = ee.FeatureCollection(\"users/wfphqgis/BND/admin_2_gaul_2015\") #admX_name\n",
    "#GBL_dfo = ee.FeatureCollection(\"users/wfphqgis/FLOOD/DFO_HistoricalFloodEvents\")\n",
    "#GBL_dfo = ee.FeatureCollection(\"users/wfphqgis/FLOOD/DFO_HistoricalFloodEvents_M\")\n",
    "\n",
    "# wfp_adm0 = GBL_adm0.filter(ee.Filter.inList\n",
    "#                            ('iso3',['DRC','NIC','HND','GTM','CAF','IRQ','LBY','BGD','MYM','COL','CIV',\n",
    "#                                     'BFA','SSD','YEM','SYR','CAM','NIG','DRC','MOZ','PHL','LBN','LKA',\n",
    "#                                     'ZWE','BEN','TGO','GHA','TUR','IND','MLI','PAN','SOM','TCD','NGA',\n",
    "#                                     'IDN','GIN','PAK','TZA','IRN','TJK','AFG','IRQ','SLE','VEN','VNM',\n",
    "#                                     'CMR','GMB','GNB','LBR','MRT','NER','SDN','MRT','MMR','LAO']))\n",
    "\n",
    "# wfp_adm0 = GBL_adm0.filter(ee.Filter.inList\n",
    "#                            ('iso3',['PHL']))\n",
    "\n",
    "# wfp_adm0 = GBL_adm0.filter(ee.Filter.inList\n",
    "#                            ('iso3',['CAF', 'ETH', 'SOM', 'DRC','COD', 'BFA', 'CAM',\n",
    "#                                    'SSD', 'NIG','MLI','ZWE', 'UGA', 'MWI']))\n",
    "# L3\n",
    "# ['SSD','YEM','SYR','CAM','NIG','DRC','MOZ']\n",
    "# L2\n",
    "# ['MLI','CAF','IRQ','LBY','BGD','MYM','COL', 'BFA']\n",
    "# M\n",
    "# ['DRC','NIC','HND','GTM']\n",
    "# Other\n",
    "# ['DRC','NIC','HND','GTM','MLI','CAF','IRQ','LBY','BGD','MYM','COL',\n",
    "# 'BFA','SSD','YEM','SYR','CAM','NIG','DRC','MOZ','PHL','LBN','LKA',\n",
    "# 'ZWE','BEN','TGO','GHA','TUR','IND','MLI','PAN','SOM','TCD','NGA',\n",
    "# 'IDN','GIN','PAK','TZA','IRN','TJK','AFG','IRQ','SLE']\n",
    "\n",
    "# Should work globally..\n",
    "# wfp_adm0 = GBL_adm0.filter(ee.Filter.inList\n",
    "#                            ('iso3',iso_global_list))\n",
    "\n",
    "# Togo, Benin, Ghana, Mali, Codivor, SSD, CAR, PANAMA\n",
    "\n",
    "#dfo = GBL_dfo.filterBounds(wfp_adm0)\n",
    "wfp_aoi = ee.FeatureCollection(\"projects/unwfp/HQGIS/fbf/Maguindanao_UID\")\n",
    "#wfp_aoi = GBL_adm2.filterBounds(dfo)\n",
    "wfp_adm0 = ee.FeatureCollection(\"projects/unwfp/HQGIS/fbf/Maguindanao_D\")\n",
    "#dfodata = eeconvert.fcToGdf(GBL_dfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEE data calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GSMaP = ee.ImageCollection('JAXA/GPM_L3/GSMaP/v6/operational')\n",
    "precipitation = GSMaP.select('hourlyPrecipRate')\n",
    "\n",
    "worldpop = ee.ImageCollection('WorldPop/GP/100m/pop').filter(ee.Filter.equals('year', 2020))\n",
    "wpop2020 = worldpop.select('population').reduce(ee.Reducer.max()).clip(wfp_adm0)\n",
    "\n",
    "ciesn2020 = ee.ImageCollection('CIESIN/GPWv4/unwpp-adjusted-population-count')\n",
    "ciesn2020_pop = ciesn2020.select('population-count').reduce(ee.Reducer.max()).clip(wfp_adm0)\n",
    "\n",
    "jrc20yrp = ee.Image('users/wfphqgis/HAZ/floodMapGL_rp20y')\n",
    "jrc_1m_remap = jrc20yrp.lte(14)\n",
    "jrc_1m_depth = jrc_1m_remap.remap([1,2,3,4,5,6,7,8,9,10,11,12,13,14],\n",
    "                                  [1,1,1,1,1,1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "hectares = ee.Image.pixelArea().divide(10000)\n",
    "\n",
    "hectares_jrc = jrc20yrp.multiply(hectares)\n",
    "\n",
    "pop_haz_area = wpop2020.multiply(jrc_1m_depth)\n",
    "#pop_haz_area = ciesn2020_pop.multiply(jrc_1m_depth)\n",
    "\n",
    "#Change\n",
    "pxr = ee.Image('users/wfphqgis/CLIM/Global_IDF')\n",
    "pxr_3days = pxr.select('b12') #band 12 for 72hours (3Days) band 14 is 120hours (5days) and \n",
    "pxr_3days_vector = spatial_red(pxr_3days,ee.Reducer.mode(),30000)\n",
    "\n",
    "#Uncomment for GFS data (update datetime is not yet fixed)\n",
    "#gfs_fc = ee.ImageCollection('NOAA/GFS0P25').select(\"total_precipitation_surface\").filter(ee.Filter.eq('creation_time',ee.Date(0).update(2019,7,21,6,0,0)\n",
    "#                                                                                                      .millis())).filter(ee.Filter.eq('forecast_hours',72)).sum()\n",
    "#gfs_fc72h_res = gfs_fc.resample('bilinear').reproject(crs=gfs_fc.projection(), scale=10000).clip(wfp_adm0)\n",
    "\n",
    "#vam = ee.Image('users/wfphqgis/CLIM/wld_cli_rainfall_threshold_q96_25yr_chirps_wfp')\n",
    "#vam_vector = spatial_red(pxr_3days,ee.Reducer.mode(),5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEE Datetime for GPM accumulated Precipitation\n",
    "day0 = datetime.today()\n",
    "hrs24 = day0 - timedelta(days=1)\n",
    "hrs48 = day0 - timedelta(days=2)\n",
    "hrs72 = day0 - timedelta(days=3)\n",
    "day7 = day0 - timedelta(days=7)\n",
    "\n",
    "#Temporal Reducer\n",
    "gpm_precip_24h = precipitation.filter(ee.Filter.date(hrs24, day0))\n",
    "gpm_precip_48h = precipitation.filter(ee.Filter.date(hrs48, day0))\n",
    "gpm_precip_72h = precipitation.filter(ee.Filter.date(hrs72, day0))\n",
    "gpm_precip_day7 = precipitation.filter(ee.Filter.date(day7, day0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/miniconda2/envs/adamf/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate Data loaded..\n"
     ]
    }
   ],
   "source": [
    "#Changed to WorldClimV2\n",
    "band_month = datetime.today().strftime(\"%m\")\n",
    "#band_month = strptime(run_date,'%b').tm_mon\n",
    "s_bm = str(band_month)\n",
    "dff_wc_rename = get_wc()\n",
    "#dff_ecmwf_rename = get_ecmwf()\n",
    "dff_sm2_rename = get_sm2map()\n",
    "print('Climate Data loaded..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial Reducer\n",
    "gpm72h = gpm_precip_72h.sum().rename('72h').clip(wfp_aoi)\n",
    "gsmap_vector_mean = spatial_red(gpm72h,ee.Reducer.mode(),500)\n",
    "wpop_vector = spatial_red(wpop2020,ee.Reducer.sum(),95)\n",
    "jrc_vector = spatial_red(jrc_1m_depth,ee.Reducer.sum(),1000) #1km resolution all models\n",
    "exp_vector = spatial_red(pop_haz_area,ee.Reducer.sum(),1000) #95 for WorldPop and 1000 for CIESN\n",
    "\n",
    "#Change\n",
    "ciesn_vector = spatial_red(ciesn2020_pop,ee.Reducer.sum(),1000)\n",
    "#gfs_fc72h_vector = spatial_red(gfs_fc72h_res,ee.Reducer.mode(),10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Global parameters. Please wait...\n"
     ]
    }
   ],
   "source": [
    "print('Computing Global parameters. Please wait...')\n",
    "df_precip_m = eeconvert.fcToGdf(gsmap_vector_mean)\n",
    "df_pop = eeconvert.fcToGdf(wpop_vector)\n",
    "df_jrc = eeconvert.fcToGdf(jrc_vector)\n",
    "df_exp = eeconvert.fcToGdf(exp_vector)\n",
    "\n",
    "#Change\n",
    "df_pxr = eeconvert.fcToGdf(pxr_3days_vector)\n",
    "df_pop1km = eeconvert.fcToGdf(ciesn_vector)\n",
    "#df_gfs = eeconvert.fcToGdf(gfs_fc72h_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to FTP!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1029110300TP.tiff'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ECMWF datetime format for FTP (Temporary Solution while migrating to Windows)\n",
    "forecast = datetime.today()\n",
    "fc_fmt = forecast.strftime(\"%m%d\")\n",
    "days3 = forecast + timedelta(days=3)\n",
    "days5 = forecast + timedelta(days=5)\n",
    "days7 = forecast + timedelta(days=7)\n",
    "\n",
    "days3F = days3.strftime(\"%m%d\")\n",
    "days5F = days5.strftime(\"%m%d\")\n",
    "days7F = days7.strftime(\"%m%d\")\n",
    "\n",
    "ecmwf_3D_fc = fc_fmt + days3F + '00' + 'TP' + '.tiff'\n",
    "ecmwf_5D_fc = fc_fmt + days5F + '00' + 'TP' + '.tiff'\n",
    "ecmwf_7D_fc = fc_fmt + days7F + '00' + 'TP' + '.tiff'\n",
    "ecmwf_5D_fc\n",
    "# config.read(os.path.join(root, \"config.txt\"))\n",
    "# ftp_user = config.get('gisftp', 'ftp_un')\n",
    "# ftp_pw = config.get('gisftp', 'ftp_pw')\n",
    "# ftp_gis =  config.get('gisftp', 'ftp_url')\n",
    "# ftp = FTP(ftp_gis)\n",
    "# ftp.login(user=ftp_user, passwd = ftp_pw)\n",
    "# save2local = ftp.cwd(\"/ECMWF_processed\")\n",
    "\n",
    "# def grabFile(fn):\n",
    "#     filename = fn\n",
    "#     localfile = open(process_ecmwf + filename, 'wb')\n",
    "#     return ftp.retrbinary('RETR ' + filename, localfile.write, 1024)\n",
    "\n",
    "\n",
    "# grabFile(ecmwf_3D_fc)\n",
    "# grabFile(ecmwf_5D_fc)\n",
    "# grabFile(ecmwf_7D_fc)\n",
    "\n",
    "# ftp.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.remove('UID')\n",
    "l\n",
    "# print(l)\n",
    "[\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " 'geometry']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alert data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff_pop = df_pop.drop(columns = ['CC_2','ENGTYPE_2','GID_0','GID_1','GID_2','HASC_2','NAME_0','NAME_1','NL_NAME_1','NL_NAME_2','TYPE_2','VARNAME_2'])\n",
    "dff_pop_rename = dff_pop.rename(columns={'sum':'Pop_adm2_WPOP2020'})\n",
    "\n",
    "dff_precip = df_precip_m.drop(columns = l)\n",
    "dff_p_rename = dff_precip.rename(columns={'mode':'3D_acc_precip'})\n",
    "\n",
    "dff_jrc = df_jrc.drop(columns = l)\n",
    "dff_jrc_rename = dff_jrc.rename(columns={'sum':'JRC_Flood_Haz'})\n",
    "\n",
    "dff_exp = df_exp.drop(columns = l)\n",
    "dff_exp_rename = dff_exp.rename(columns={'sum':'Exp_Pop_1m'})\n",
    "\n",
    "#Change PXR RFIDF\n",
    "dff_pxr = df_pxr.drop(columns = l)\n",
    "dff_pxr_rename = dff_pxr.rename(columns={'mode':'MaxTP_3D'})\n",
    "\n",
    "dff_pop1km = df_pop1km.drop(columns = l)\n",
    "dff_pop1km_rename = dff_pop1km.rename(columns={'sum':'Pop_adm2_CSN2019'})\n",
    "\n",
    "#dff_gfs = df_gfs.drop(columns = ['adm0_name', 'adm1_name','adm2_name', 'adm0_code', 'adm1_code','disp_area','geometry','status'])\n",
    "#df_gfs_rename = dff_gfs.rename(columns={'mode':'GFS_3D'})\n",
    "\n",
    "#Merge all DF\n",
    "pre_merged = dff_p_rename.merge(dff_sm2_rename, on='UID').merge(dff_pop_rename,on='UID').merge(dff_jrc_rename,on='UID').merge(dff_exp_rename,on='UID').merge(dff_pxr_rename,on='UID').merge(dff_pop1km_rename,on='UID')#.merge(df_gfs_rename,on='adm2_code')\n",
    "pre_merged['MaxTP_3D'] = pre_merged['MaxTP_3D'] * 1000\n",
    "pre_merged = pre_merged.round(3)\n",
    "pre_merged.tail()\n",
    "type(pre_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_merged = gpd.GeoDataFrame(pre_merged, geometry=pre_merged['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Alerts created...\n"
     ]
    }
   ],
   "source": [
    "### For local testing not connected to WFP domain (should have data locally)\n",
    "#ecmwf_F_3D = '/Users/michael/GEO/adam-floods-alert/processing/process_ecmwf/0830090200TP.tiff'\n",
    "#ecmwf_F_5D = '/Users/michael/GEO/adam-floods-alert//processing/process_ecmwf/0830090400TP.tiff'\n",
    "\n",
    "### Uncomment for NRT\n",
    "ecmwf_F_3D = process_ecmwf + ecmwf_3D_fc\n",
    "ecmwf_F_5D = process_ecmwf + ecmwf_5D_fc\n",
    "ecmwf_F_3D_stats = zonal_stats(pre_merged, ecmwf_F_3D, prefix='ecmwf3D_',geojson_out=True)\n",
    "ecmwf_F_5D_stats = zonal_stats(pre_merged, ecmwf_F_5D, prefix='ecmwf5D_',geojson_out=True)\n",
    "ecmwf_F_3D_gdf = GeoDataFrame.from_features(ecmwf_F_3D_stats)\n",
    "ecmwf_F_5D_gdf = GeoDataFrame.from_features(ecmwf_F_5D_stats)\n",
    "\n",
    "ecmwf_F_3D_gdf['ecmwf3D_mean'] = ecmwf_F_3D_gdf['ecmwf3D_mean'] * 1000 # converts TP values from meters to mm\n",
    "ecmwf_F_5D_gdf['ecmwf5D_mean'] = ecmwf_F_5D_gdf['ecmwf5D_mean'] * 1000 # converts TP values from meters to mm\n",
    "\n",
    "\n",
    "dfNew = ecmwf_F_5D_gdf.merge(ecmwf_F_3D_gdf, left_index=True, right_index=True,\n",
    "                 how='outer', suffixes=('', '_y'))\n",
    "dfNew.drop(list(dfNew.filter(regex='_y$')), axis=1, inplace=True)\n",
    "to_drop = ['ecmwf5D_count','ecmwf5D_max','ecmwf5D_min','ecmwf3D_count','ecmwf3D_max','ecmwf3D_min']\n",
    "gbl_alert = dfNew.drop(columns=to_drop).round(2)\n",
    "gbl_alert['uuid'] = [uuid.uuid4() for _ in range(len(gbl_alert.index))]\n",
    "print('Global Alerts created...')\n",
    "#gbl_alert = gbl_alert.loc[(gbl_alert['3D_acc_precip'] >= 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>3D_acc_precip</th>\n",
       "      <th>Exp_Pop_1m</th>\n",
       "      <th>JRC_Flood_Haz</th>\n",
       "      <th>MaxTP_3D</th>\n",
       "      <th>Mean_Prec</th>\n",
       "      <th>NAME_2</th>\n",
       "      <th>Pop_adm2_CSN2019</th>\n",
       "      <th>Pop_adm2_WPOP2020</th>\n",
       "      <th>UID</th>\n",
       "      <th>ecmwf5D_mean</th>\n",
       "      <th>ecmwf3D_mean</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>MULTIPOLYGON (((124.01444 7.31806, 124.01472 7...</td>\n",
       "      <td>35.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.19</td>\n",
       "      <td>286.0</td>\n",
       "      <td>Parang</td>\n",
       "      <td>153328.22</td>\n",
       "      <td>23818.69</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26f6bb65-3450-4c5f-8588-256e7f5e4652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>POLYGON ((124.20306 7.26472, 124.20333 7.26444...</td>\n",
       "      <td>25.18</td>\n",
       "      <td>201.07</td>\n",
       "      <td>64.76</td>\n",
       "      <td>101.54</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Sultan Kudarat</td>\n",
       "      <td>184744.93</td>\n",
       "      <td>33403.90</td>\n",
       "      <td>33</td>\n",
       "      <td>47.75</td>\n",
       "      <td>28.17</td>\n",
       "      <td>5250d481-2ffb-4d17-adc8-735bd8b868d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>POLYGON ((124.20917 7.28040, 124.21200 7.28252...</td>\n",
       "      <td>22.47</td>\n",
       "      <td>20.85</td>\n",
       "      <td>5.76</td>\n",
       "      <td>70.19</td>\n",
       "      <td>274.0</td>\n",
       "      <td>Sultan Mastura</td>\n",
       "      <td>31666.06</td>\n",
       "      <td>11539.76</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5fef52a0-f5ef-49d9-8d0e-fef5dce48c99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>POLYGON ((124.04474 6.85151, 124.07478 6.85174...</td>\n",
       "      <td>21.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.78</td>\n",
       "      <td>283.0</td>\n",
       "      <td>Upi</td>\n",
       "      <td>53440.67</td>\n",
       "      <td>57915.17</td>\n",
       "      <td>38</td>\n",
       "      <td>53.07</td>\n",
       "      <td>37.78</td>\n",
       "      <td>83f0f878-0a17-47b6-baf7-1bef04d76b17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>POLYGON ((124.34370 7.13884, 124.34722 7.13745...</td>\n",
       "      <td>23.39</td>\n",
       "      <td>48.63</td>\n",
       "      <td>118.77</td>\n",
       "      <td>101.54</td>\n",
       "      <td>218.0</td>\n",
       "      <td>Northern Kabuntalan</td>\n",
       "      <td>35076.51</td>\n",
       "      <td>5378.47</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3b23f101-132b-4722-a690-a99f60097112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry  3D_acc_precip  \\\n",
       "51  MULTIPOLYGON (((124.01444 7.31806, 124.01472 7...          35.14   \n",
       "52  POLYGON ((124.20306 7.26472, 124.20333 7.26444...          25.18   \n",
       "53  POLYGON ((124.20917 7.28040, 124.21200 7.28252...          22.47   \n",
       "54  POLYGON ((124.04474 6.85151, 124.07478 6.85174...          21.70   \n",
       "55  POLYGON ((124.34370 7.13884, 124.34722 7.13745...          23.39   \n",
       "\n",
       "    Exp_Pop_1m  JRC_Flood_Haz  MaxTP_3D  Mean_Prec               NAME_2  \\\n",
       "51        0.00           0.00     70.19      286.0               Parang   \n",
       "52      201.07          64.76    101.54      268.0       Sultan Kudarat   \n",
       "53       20.85           5.76     70.19      274.0       Sultan Mastura   \n",
       "54        0.00           0.00     64.78      283.0                  Upi   \n",
       "55       48.63         118.77    101.54      218.0  Northern Kabuntalan   \n",
       "\n",
       "    Pop_adm2_CSN2019  Pop_adm2_WPOP2020  UID  ecmwf5D_mean  ecmwf3D_mean  \\\n",
       "51         153328.22           23818.69   29           NaN           NaN   \n",
       "52         184744.93           33403.90   33         47.75         28.17   \n",
       "53          31666.06           11539.76   34           NaN           NaN   \n",
       "54          53440.67           57915.17   38         53.07         37.78   \n",
       "55          35076.51            5378.47   24           NaN           NaN   \n",
       "\n",
       "                                    uuid  \n",
       "51  26f6bb65-3450-4c5f-8588-256e7f5e4652  \n",
       "52  5250d481-2ffb-4d17-adc8-735bd8b868d9  \n",
       "53  5fef52a0-f5ef-49d9-8d0e-fef5dce48c99  \n",
       "54  83f0f878-0a17-47b6-baf7-1bef04d76b17  \n",
       "55  3b23f101-132b-4722-a690-a99f60097112  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbl_alert.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before 19 June 2019\n",
    "#map_me = alert.loc[(alert['status'] == 'red') | (alert['P100'] == True) | (alert['ecmwf3D_mean'] > 50)]\n",
    "\n",
    "### Deployed version 19 June 2019\n",
    "#map_me = alert.loc[((alert['status'] == 'green') & (alert['P60'] == True)) | ((alert['status'] == 'red') & (alert['ecmwf3D_mean'] > alert['Mean_Prec']*0.6))] \n",
    "\n",
    "#map_me = alert.loc[(alert['3D_acc_precip'] > alert['MaxInt_3D_x']) | alert['P80'] == True]\n",
    "#map_me.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amsr2 = get_amsr2()\n",
    "# amsr2_stats = zonal_stats(alert, amsr2, prefix='amsr2',geojson_out=True)\n",
    "# zonal_ppt_gdf = GeoDataFrame.from_features(amsr2_stats)\n",
    "# zonal_ppt_gdf = zonal_ppt_gdf.loc[(zonal_ppt_gdf['amsr2max'] > 10000)]\n",
    "# zonal_ppt_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x):\n",
    "    if x >= 50000:\n",
    "        return \"red\"\n",
    "    elif x <= 10000:\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"orange\"\n",
    "    \n",
    "def func2(x):\n",
    "    if x >= 500000:\n",
    "        return \"red\"\n",
    "    elif x <= 10000:\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"orange\"\n",
    "\n",
    "# def func3(df):\n",
    "#     if df['nowcast_mod'] == True & df['pop_status'] == 'red':\n",
    "#         return \"green\"\n",
    "#     elif df['nowcast_high'] == True & df['pop_status'] == 'red':\n",
    "#         return \"orange\"\n",
    "#     elif df['forecast_high'] == True & df['pop_status'] == 'red':\n",
    "#         return \"red\"\n",
    "#     else:\n",
    "#         pass\n",
    "# gbl_alert['status'] = gbl_alert.apply(func3)\n",
    "\n",
    "#ABDELS COMMENTS\n",
    "#map_me = alert.loc[((alert['3D_acc_precip'] + alert['ecmwf3D_mean']) > alert['Mean_Prec'])] \n",
    "\n",
    "#Conditions goes here. Needs more work here\n",
    "#gbl_alert = gbl_alert.loc[gbl_alert['3D_acc_precip'] >=50]\n",
    "gbl_alert['pop_status'] = gbl_alert['Pop_adm2_CSN2019'].apply(func2)\n",
    "gbl_alert['exp_status'] = gbl_alert['Exp_Pop_1m'].apply(func1)\n",
    "\n",
    "#gbl_alert['P60'] = (gbl_alert['3D_acc_precip'] > gbl_alert['Mean_Prec']*0.60)\n",
    "#gbl_alert['P80'] = (gbl_alert['3D_acc_precip'] > gbl_alert['Mean_Prec']*0.80)\n",
    "#gbl_alert['P100'] = (gbl_alert['3D_acc_precip'] > gbl_alert['Mean_Prec'])\n",
    "#alert['ecmwf'] = alert['ECMWF_Mean_Prec'].apply(lambda x: x*1000) #check with abdel TP values\n",
    "\n",
    "#alert = alert[['adm0_name','adm1_name','adm2_name','adm2_code','status','MaxTP_3D','Mean_Prec','3D_acc_precip','ecmwf3D_mean','ecmwf5D_mean','Est_pop_adm2','JRC_Flood_Haz','Exp_Pop_1m','P60','P80','P100']]\n",
    "\n",
    "#Condition 1\n",
    "#gbl_alert['nowcast_low'] = (gbl_alert['3D_acc_precip'] > gbl_alert['MaxTP_3D']).astype(int)\n",
    "#Condition 2\n",
    "#gbl_alert['nowcast_mod'] = ((gbl_alert['3D_acc_precip'] + gbl_alert['ecmwf3D_mean']) > gbl_alert['MaxTP_3D']).astype(int)\n",
    "gbl_alert['nowcast_mod'] = (gbl_alert['3D_acc_precip'] > gbl_alert['MaxTP_3D']).astype(int)\n",
    "#Condition 3\n",
    "gbl_alert['nowcast_high'] = (gbl_alert['3D_acc_precip'] > gbl_alert['Mean_Prec']).astype(int)\n",
    "#Condition 3\n",
    "gbl_alert['forecast_high'] = ((gbl_alert['3D_acc_precip'] + gbl_alert['ecmwf3D_mean'] > (gbl_alert['Mean_Prec'] + gbl_alert['Mean_Prec']*0.60)) | (gbl_alert['3D_acc_precip'] + gbl_alert['ecmwf5D_mean'] > (gbl_alert['Mean_Prec'] + gbl_alert['Mean_Prec']*0.60))).astype(int)\n",
    "#gbl_alert = gbl_alert.loc[(gbl_alert['nowcast_mod'] == True & gbl_alert['pop_status'] == 'red') | (gbl_alert['nowcast_high'] == True) | (gbl_alert['forecast_high'] == True)]\n",
    "\n",
    "#People Living only\n",
    "# gbl_alert = gbl_alert.loc[((gbl_alert['nowcast_mod'] == True) & (gbl_alert['pop_status'] == 'red') | \n",
    "#                            (gbl_alert['nowcast_high'] == True) & (gbl_alert['pop_status'] == 'red') | \n",
    "#                            (gbl_alert['forecast_high'] == True) & (gbl_alert['pop_status'] == 'red'))]\n",
    "\n",
    "##Exposure\n",
    "gbl_alert.loc[(gbl_alert['3D_acc_precip'] >= 50), 'status'] = 'white'\n",
    "gbl_alert.loc[(gbl_alert['nowcast_mod'] == True) & (gbl_alert['exp_status'] == 'red'),'status']  = 'yellow'\n",
    "gbl_alert.loc[(gbl_alert['nowcast_high'] == True) & (gbl_alert['exp_status'] == 'red'), 'status'] = 'orange'\n",
    "gbl_alert.loc[(gbl_alert['forecast_high'] == True) & (gbl_alert['exp_status'] == 'red'), 'status'] = 'red'\n",
    "final_df = gbl_alert.loc[(gbl_alert['status'] == 'yellow') | (gbl_alert['status'] == 'orange')| (gbl_alert['status'] == 'red')| (gbl_alert['status'] == 'white')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>3D_acc_precip</th>\n",
       "      <th>Exp_Pop_1m</th>\n",
       "      <th>JRC_Flood_Haz</th>\n",
       "      <th>MaxTP_3D</th>\n",
       "      <th>Mean_Prec</th>\n",
       "      <th>NAME_2</th>\n",
       "      <th>Pop_adm2_CSN2019</th>\n",
       "      <th>Pop_adm2_WPOP2020</th>\n",
       "      <th>UID</th>\n",
       "      <th>ecmwf5D_mean</th>\n",
       "      <th>ecmwf3D_mean</th>\n",
       "      <th>uuid</th>\n",
       "      <th>pop_status</th>\n",
       "      <th>exp_status</th>\n",
       "      <th>nowcast_mod</th>\n",
       "      <th>nowcast_high</th>\n",
       "      <th>forecast_high</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((124.62534 6.64509, 124.62740 6.64255...</td>\n",
       "      <td>51.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.89</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Tacurong City</td>\n",
       "      <td>96031.74</td>\n",
       "      <td>109627.08</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a1e43536-bb91-4b72-90ed-a3ec1197973d</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MULTIPOLYGON (((124.79241 6.64268, 124.79258 6...</td>\n",
       "      <td>52.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.88</td>\n",
       "      <td>198.0</td>\n",
       "      <td>President Quirino</td>\n",
       "      <td>47766.70</td>\n",
       "      <td>59846.69</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7d83241e-cebd-4f7b-97c8-577b72e936d6</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POLYGON ((124.75507 6.73490, 124.75927 6.72952...</td>\n",
       "      <td>52.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.72</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Buluan</td>\n",
       "      <td>47202.60</td>\n",
       "      <td>62576.04</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2c14d971-6099-4aed-ba86-167e0a6a4b1f</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>POLYGON ((124.74592 6.78199, 124.74841 6.75499...</td>\n",
       "      <td>52.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.25</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Pandag</td>\n",
       "      <td>31286.74</td>\n",
       "      <td>35649.57</td>\n",
       "      <td>28</td>\n",
       "      <td>63.54</td>\n",
       "      <td>40.53</td>\n",
       "      <td>08eab947-09dd-4645-9d7c-2f24efe170a1</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry  3D_acc_precip  \\\n",
       "0   POLYGON ((124.62534 6.64509, 124.62740 6.64255...          51.86   \n",
       "18  MULTIPOLYGON (((124.79241 6.64268, 124.79258 6...          52.21   \n",
       "24  POLYGON ((124.75507 6.73490, 124.75927 6.72952...          52.21   \n",
       "44  POLYGON ((124.74592 6.78199, 124.74841 6.75499...          52.21   \n",
       "\n",
       "    Exp_Pop_1m  JRC_Flood_Haz  MaxTP_3D  Mean_Prec             NAME_2  \\\n",
       "0          0.0            0.0    124.89      193.0      Tacurong City   \n",
       "18         0.0            0.0    108.88      198.0  President Quirino   \n",
       "24         0.0            0.0    131.72      190.0             Buluan   \n",
       "44         0.0            0.0     71.25      193.0             Pandag   \n",
       "\n",
       "    Pop_adm2_CSN2019  Pop_adm2_WPOP2020  UID  ecmwf5D_mean  ecmwf3D_mean  \\\n",
       "0           96031.74          109627.08   55           NaN           NaN   \n",
       "18          47766.70           59846.69   54           NaN           NaN   \n",
       "24          47202.60           62576.04    7           NaN           NaN   \n",
       "44          31286.74           35649.57   28         63.54         40.53   \n",
       "\n",
       "                                    uuid pop_status exp_status  nowcast_mod  \\\n",
       "0   a1e43536-bb91-4b72-90ed-a3ec1197973d     orange      green            0   \n",
       "18  7d83241e-cebd-4f7b-97c8-577b72e936d6     orange      green            0   \n",
       "24  2c14d971-6099-4aed-ba86-167e0a6a4b1f     orange      green            0   \n",
       "44  08eab947-09dd-4645-9d7c-2f24efe170a1     orange      green            0   \n",
       "\n",
       "    nowcast_high  forecast_high status  \n",
       "0              0              0  white  \n",
       "18             0              0  white  \n",
       "24             0              0  white  \n",
       "44             0              0  white  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('/Users/michael/GEO/adam-floods-alert/data/alert/Extreme_rainfall_alert_beta_20200725_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = final_df.groupby('status')['status'].value_counts()\n",
    "sss = summary.values.tolist()\n",
    "\n",
    "try:\n",
    "    w = ''\n",
    "    y = ''\n",
    "    o = ''\n",
    "    r = ''\n",
    "    w = summary[0]\n",
    "    y = summary[1]\n",
    "    o = summary[2]\n",
    "    r = summary[3]\n",
    "except Exception:\n",
    "    pass \n",
    "\n",
    "### GIS Officers in the area    \n",
    "# recip = pd.read_excel(root + '/wfp' + '/wfp_gis.xlsx', index_col=0, sheet_name='GIS_officer')\n",
    "# input_countries = map_me['adm0_name'].to_list()\n",
    "# countries = {}\n",
    "# for country in pycountry.countries:\n",
    "#     countries[country.name] = country.alpha_3\n",
    "# c = [countries.get(c, 'Unknown code') for c in input_countries]\n",
    "# codes = list(set(c))\n",
    "# codes_df = pd.DataFrame(codes,columns=['ISO3'])\n",
    "\n",
    "# hoomans = []\n",
    "\n",
    "# for i in codes:\n",
    "#     gis_officers = recip.loc[recip['ISO3']==i]    \n",
    "#     gis_officers_ls = gis_officers.values.tolist()\n",
    "#     #gis_officer_dict = dict(gis_officers_ls)\n",
    "#     hoomans.append(gis_officers_ls)   \n",
    "# list2 = [x for x in hoomans if x != []]\n",
    "# l = [i.strip('[]') if type(i) == str else str(i) for i in list2]\n",
    "# a = \"\\n\".join(l)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status  status\n",
       "white   white     4\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>3D_acc_precip_x</th>\n",
       "      <th>Mean_Prec_x</th>\n",
       "      <th>NAME_2_x</th>\n",
       "      <th>Pop_adm2_WPOP2020_x</th>\n",
       "      <th>geometry</th>\n",
       "      <th>JRC_Flood_Haz_x</th>\n",
       "      <th>Exp_Pop_1m_x</th>\n",
       "      <th>MaxTP_3D_x</th>\n",
       "      <th>Pop_adm2_CSN2019_x</th>\n",
       "      <th>ecmwf5D_mean</th>\n",
       "      <th>ecmwf3D_mean</th>\n",
       "      <th>uuid</th>\n",
       "      <th>pop_status</th>\n",
       "      <th>exp_status</th>\n",
       "      <th>nowcast_mod</th>\n",
       "      <th>nowcast_high</th>\n",
       "      <th>forecast_high</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>51.863</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Tacurong City</td>\n",
       "      <td>109627.077</td>\n",
       "      <td>POLYGON ((124.62534 6.64509, 124.62740 6.64255...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.887</td>\n",
       "      <td>96031.744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a1e43536-bb91-4b72-90ed-a3ec1197973d</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>52.209</td>\n",
       "      <td>198.0</td>\n",
       "      <td>President Quirino</td>\n",
       "      <td>59846.690</td>\n",
       "      <td>MULTIPOLYGON (((124.79241 6.64268, 124.79258 6...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.884</td>\n",
       "      <td>47766.695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7d83241e-cebd-4f7b-97c8-577b72e936d6</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>52.209</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Buluan</td>\n",
       "      <td>62576.037</td>\n",
       "      <td>POLYGON ((124.75507 6.73490, 124.75927 6.72952...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.724</td>\n",
       "      <td>47202.599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2c14d971-6099-4aed-ba86-167e0a6a4b1f</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>52.209</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Pandag</td>\n",
       "      <td>35649.569</td>\n",
       "      <td>POLYGON ((124.74592 6.78199, 124.74841 6.75499...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.248</td>\n",
       "      <td>31286.735</td>\n",
       "      <td>63.54</td>\n",
       "      <td>40.53</td>\n",
       "      <td>08eab947-09dd-4645-9d7c-2f24efe170a1</td>\n",
       "      <td>orange</td>\n",
       "      <td>green</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID  3D_acc_precip_x  Mean_Prec_x           NAME_2_x  Pop_adm2_WPOP2020_x  \\\n",
       "0   55           51.863        193.0      Tacurong City           109627.077   \n",
       "1   54           52.209        198.0  President Quirino            59846.690   \n",
       "2    7           52.209        190.0             Buluan            62576.037   \n",
       "3   28           52.209        193.0             Pandag            35649.569   \n",
       "\n",
       "                                            geometry  JRC_Flood_Haz_x  \\\n",
       "0  POLYGON ((124.62534 6.64509, 124.62740 6.64255...              0.0   \n",
       "1  MULTIPOLYGON (((124.79241 6.64268, 124.79258 6...              0.0   \n",
       "2  POLYGON ((124.75507 6.73490, 124.75927 6.72952...              0.0   \n",
       "3  POLYGON ((124.74592 6.78199, 124.74841 6.75499...              0.0   \n",
       "\n",
       "   Exp_Pop_1m_x  MaxTP_3D_x  Pop_adm2_CSN2019_x  ecmwf5D_mean  ecmwf3D_mean  \\\n",
       "0           0.0     124.887           96031.744           NaN           NaN   \n",
       "1           0.0     108.884           47766.695           NaN           NaN   \n",
       "2           0.0     131.724           47202.599           NaN           NaN   \n",
       "3           0.0      71.248           31286.735         63.54         40.53   \n",
       "\n",
       "                                   uuid pop_status exp_status  nowcast_mod  \\\n",
       "0  a1e43536-bb91-4b72-90ed-a3ec1197973d     orange      green            0   \n",
       "1  7d83241e-cebd-4f7b-97c8-577b72e936d6     orange      green            0   \n",
       "2  2c14d971-6099-4aed-ba86-167e0a6a4b1f     orange      green            0   \n",
       "3  08eab947-09dd-4645-9d7c-2f24efe170a1     orange      green            0   \n",
       "\n",
       "   nowcast_high  forecast_high status  \n",
       "0             0              0  white  \n",
       "1             0              0  white  \n",
       "2             0              0  white  \n",
       "3             0              0  white  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo = pre_merged.merge(final_df, on='UID')\n",
    "geo.drop(list(geo.filter(regex='_y$')), axis=1, inplace=True)\n",
    "geo = geo.rename(columns={'geometry_x':'geometry'})\n",
    "geo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alert_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-91a7eaf59ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_alert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_alert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#truncates the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malert_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcur2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alert_engine' is not defined"
     ]
    }
   ],
   "source": [
    "df_alert = pd.DataFrame(final_df)\n",
    "df_alert.head(0).to_sql(alert_data, alert_engine, if_exists='replace',index=False) #truncates the table\n",
    "conn2 = alert_engine.raw_connection()\n",
    "cur2 = conn2.cursor()\n",
    "output2 = io.StringIO()\n",
    "df_alert.to_csv(output2, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save WHITE alerts to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.read(os.path.join(root, \"config.txt\"))\n",
    "dbserver_out = config.get('db_out','dbserver')\n",
    "dbname_out = config.get('db_out','dbname')\n",
    "dbuser_out = config.get('db_out','dbuser')\n",
    "dbpword_out = config.get('db_out','dbpword')\n",
    "dbport_out = config.get('db_out','dbport')\n",
    "engine = create_engine('postgresql+psycopg2://' + dbuser_out + ':' + dbpword_out + '@' + dbserver_out + ':' + dbport_out + '/' + dbname_out)\n",
    "\n",
    "try:\n",
    "    df = pd.DataFrame(final_df)\n",
    "    df.head(0).to_sql(whitelist_data, engine, if_exists='replace',index=False) #truncates the table\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    output = io.StringIO()\n",
    "    df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, whitelist_data, null=\"\") # null values become ''\n",
    "    conn.commit()\n",
    "\n",
    "    sqlstr = \"ALTER TABLE {table_name} ALTER COLUMN geometry TYPE geometry;\".format(** {\n",
    "                'table_name': whitelist_data})\n",
    "\n",
    "    cur.execute(sqlstr)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    print('White Alerts Sent to DB')\n",
    "except Exception:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeometryDtype' object has no attribute 'base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert GeometryArray to numpy.ndarray",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-86561af67a75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhitelist_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#truncates the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m         )\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         )\n\u001b[1;32m   1316\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, pandas_sql_engine, frame, index, if_exists, prefix, index_label, schema, keys, dtype)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# We want to initialize based on a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_table_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;31m# no data provided, read-only mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_create_table_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrimaryKeyConstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0mcolumn_names_and_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_column_names_and_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlalchemy_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         columns = [\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_get_column_names_and_types\u001b[0;34m(self, dtype_mapper)\u001b[0m\n\u001b[1;32m    858\u001b[0m         column_names_and_types += [\n\u001b[1;32m    859\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         ]\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    858\u001b[0m         column_names_and_types += [\n\u001b[1;32m    859\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         ]\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/adamf/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_sqlalchemy_type\u001b[0;34m(self, col)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# Infer type of column, while ignoring missing values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Needed for inserting typed data containing NULLs, GH 8778.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0mcol_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         from sqlalchemy.types import (\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib._try_infer_map\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeometryDtype' object has no attribute 'base'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(final_df)\n",
    "df.head(0).to_sql(whitelist_data, engine, if_exists='replace',index=False) #truncates the table\n",
    "conn = engine.raw_connection()\n",
    "cur = conn.cursor()\n",
    "output = io.StringIO()\n",
    "df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "output.seek(0)\n",
    "contents = output.getvalue()\n",
    "cur.copy_from(output, whitelist_data, null=\"\") # null values become ''\n",
    "conn.commit()\n",
    "\n",
    "sqlstr = \"ALTER TABLE {table_name} ALTER COLUMN geometry TYPE geometry;\".format(** {\n",
    "            'table_name': whitelist_data})\n",
    "\n",
    "cur.execute(sqlstr)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "print('White Alerts Sent to DB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save RED alerts to flood.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensing_date=('NOW-11DAYS',date_cut) #XDAYS XMONTH XWEEK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.read(os.path.join(root, \"config.txt\"))\n",
    "dbserver_al = config.get('db_alert','dbserver_a')\n",
    "dbname_al = config.get('db_alert','dbname_a')\n",
    "dbuser_al = config.get('db_alert','dbuser_a')\n",
    "dbpword_al = config.get('db_alert','dbpword_a')\n",
    "dbport_al = config.get('db_alert','dbport_a')\n",
    "alert_engine = create_engine('postgresql+psycopg2://' + dbuser_al + ':' + dbpword_al + '@' + dbserver_al + ':' + dbport_al + '/' + dbname_al)\n",
    "\n",
    "# try:\n",
    "#     if final_df.empty == False: \n",
    "#         df_alert = pd.DataFrame(final_df)\n",
    "#         df_alert.head(0).to_sql(alert_data, alert_engine, if_exists='replace',index=False) #truncates the table\n",
    "#         conn2 = alert_engine.raw_connection()\n",
    "#         cur2 = conn2.cursor()\n",
    "#         output2 = io.StringIO()\n",
    "#         df_alert.to_csv(output2, sep='\\t', header=False, index=False)\n",
    "#         output2.seek(0)\n",
    "#         contents2 = output2.getvalue()\n",
    "#         cur2.copy_from(output2, alert_data, null=\"\") # null values become ''\n",
    "#         conn2.commit()\n",
    "\n",
    "#         sqlstr2 = \"ALTER TABLE {table_name} ALTER COLUMN geometry TYPE geometry;\".format(** {\n",
    "#                     'table_name': alert_data})\n",
    "\n",
    "#         cur2.execute(sqlstr2)\n",
    "#         conn2.commit()\n",
    "#         cur2.close()\n",
    "#         print('Orange Alerts Sent to DB')\n",
    "        \n",
    "#     else:\n",
    "#         print('No Alerts for today. Check White alerts if necessary!')\n",
    "# except Exception:\n",
    "#     pass \n",
    "\n",
    "try:\n",
    "    if final_df.empty == True:\n",
    "        pass\n",
    "    else:\n",
    "        bbox = final_df.envelope\n",
    "        bbox_gdf = gpd.GeoDataFrame(gpd.GeoSeries(bbox), columns=['geometry'])\n",
    "        c = pd.concat([bbox_gdf,final_df],axis=1)\n",
    "        x = bbox.to_json()\n",
    "        m = folium.Map(tiles='cartodbpositron') #cartodbpositron #stamentoner #cartodbdark_matter\n",
    "        folium.GeoJson(x).add_to(m)\n",
    "        m.fit_bounds(m.get_bounds())\n",
    "        map_view_name = 'Map_view_' + date_cut + '.html'\n",
    "        view = m.save(map_view_path + map_view_name)\n",
    "        alert_geo = pd.DataFrame(final_df)\n",
    "        alert_content = alert_geo.drop(columns = ['geometry'])\n",
    "        att_alert = alert_content.to_csv(alert_csv_path + alert_data_name)\n",
    "        \n",
    "        recip = pd.read_excel(root + '/data/wfp' + '/wfp_gis.xlsx', index_col=0, sheet_name='GIS_officer')\n",
    "        input_countries = final_df['adm0_name'].to_list()\n",
    "        countries = {}\n",
    "        for country in pycountry.countries:\n",
    "            countries[country.name] = country.alpha_3\n",
    "        c = [countries.get(c, 'Unknown code') for c in input_countries]\n",
    "        codes = list(set(c))\n",
    "        codes_df = pd.DataFrame(codes,columns=['ISO3'])\n",
    "\n",
    "        hoomans = []\n",
    "        summary = final_df.groupby('status')['status'].value_counts()\n",
    "        sss = summary.values.tolist()\n",
    "        \n",
    "        #grouped = final_df.groupby('status')\n",
    "        #grouped = final_df.groupby('nowcast_high')#['nowcast_high'].value_counts()\n",
    "        #s_nc = grouped.values.tolist()\n",
    "        #summary_fc = gbl_alert.groupby('forecast_high')#['forecast_high'].value_counts()\n",
    "        #s_fc = summary_fc.values.tolist()\n",
    "        #for name,group in grouped:\n",
    "\n",
    "        for index, row in final_df.iterrows():\n",
    "            if row.status == 'orange':\n",
    "                get_s1_info(index)\n",
    "            if row.status == 'red':\n",
    "                get_s1_info(index)\n",
    "        \n",
    "        for i in codes:\n",
    "            gis_officers = recip.loc[recip['ISO3']==i]    \n",
    "            gis_officers_ls = gis_officers.values.tolist()\n",
    "            #gis_officer_dict = dict(gis_officers_ls)\n",
    "            hoomans.append(gis_officers_ls)   \n",
    "        list2 = [x for x in hoomans if x != []]\n",
    "        l = [i.strip('[]') if type(i) == str else str(i) for i in list2]\n",
    "        a = \"\\n\".join(l)\n",
    "        job()\n",
    "                \n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"The script took {0} seconds to complete...\".format(time.time() - execTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = final_df.envelope\n",
    "bbox_gdf = gpd.GeoDataFrame(gpd.GeoSeries(bbox), columns=['geometry'])\n",
    "c = pd.concat([bbox_gdf,final_df],axis=1)\n",
    "x = bbox.to_json()\n",
    "m = folium.Map(tiles='cartodbpositron') #cartodbpositron #stamentoner #cartodbdark_matter\n",
    "folium.GeoJson(x).add_to(m)\n",
    "m.fit_bounds(m.get_bounds())\n",
    "map_view_name = 'Map_view_' + date_cut + '.html'\n",
    "view = m.save(map_view_path + map_view_name)\n",
    "alert_geo = pd.DataFrame(final_df)\n",
    "alert_content = alert_geo.drop(columns = ['geometry'])\n",
    "att_alert = alert_content.to_csv(alert_csv_path + alert_data_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of script.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bbox = final_df.envelope\n",
    "#bbox = gbl_alert.envelope\n",
    "bbox_gdf = gpd.GeoDataFrame(gpd.GeoSeries(bbox), columns=['geometry'])\n",
    "c = pd.concat([bbox_gdf,final_df],axis=1)\n",
    "x = bbox.to_json()\n",
    "m = folium.Map(tiles='cartodbpositron') #cartodbpositron #stamentoner #cartodbdark_matter\n",
    "folium.GeoJson(x).add_to(m)\n",
    "m.fit_bounds(m.get_bounds())\n",
    "view = m.save(map_view_path + map_view_name)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working scratch do not delete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCRATCH\n",
    "# conditions = [(df['column_1'] > 5),\n",
    "#               (df['column_1'] <= 5) & (df['column_1'] > 0),\n",
    "#               (df['column_1'] == 0)]\n",
    "\n",
    "# choices = ['high','low','null']\n",
    "\n",
    "# df['column_2'] = np.select(conditions, choices, default='null')\n",
    "\n",
    "# summary_nc = gbl_alert.groupby('nowcast_high')['nowcast_high'].value_counts()\n",
    "# s_nc = summary_nc.values.tolist()\n",
    "# summary_fc = gbl_alert.groupby('forecast_high')['forecast_high'].value_counts()\n",
    "# s_fc = summary_fc.values.tolist()\n",
    "# try:\n",
    "#     nc = ''\n",
    "#     fc = ''\n",
    "#     nc = s_nc[1]\n",
    "#     fc = s_fc[1]\n",
    "# except Exception:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This works OK. \n",
    "# for name,group in grouped_nc:\n",
    "#     for i in codes:\n",
    "#         gis_officers = recip.loc[recip['ISO3']==i]    \n",
    "#         gis_officers_ls = gis_officers.values.tolist()\n",
    "#         #gis_officer_dict = dict(gis_officers_ls)\n",
    "#         hoomans.append(gis_officers_ls)   \n",
    "#     list2 = [x for x in hoomans if x != []]\n",
    "#     l = [i.strip('[]') if type(i) == str else str(i) for i in list2]\n",
    "#     a = \"\\n\".join(l)\n",
    "#     job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# while i == 0:\n",
    "#     if name == 'red':\n",
    "#         i = 0\n",
    "#         print('i am red')\n",
    "#     elif name == 'orange':\n",
    "#         i = 0\n",
    "#         print('i am orange')\n",
    "#     else:\n",
    "#         i += 1\n",
    "#         print('i am green')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name,group in grouped:\n",
    "#     if name == 'green':\n",
    "#         for i in codes:\n",
    "#             gis_officers = recip.loc[recip['ISO3']==i]    \n",
    "#             gis_officers_ls = gis_officers.values.tolist()\n",
    "#             #gis_officer_dict = dict(gis_officers_ls)\n",
    "#             hoomans.append(gis_officers_ls)   \n",
    "#         list2 = [x for x in hoomans if x != []]\n",
    "#         l = [i.strip('[]') if type(i) == str else str(i) for i in list2]\n",
    "#         a = \"\\n\".join(l)\n",
    "#         job()\n",
    "#     else:\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email works via wfp domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alert_geo = pd.DataFrame(map_me)\n",
    "# alert_content = alert_geo.drop(columns = ['geometry'])\n",
    "# att_alert = alert_content.to_csv(alert_csv_path + alert_data_name)\n",
    "\n",
    "# #map_view_name = 'Map_view_' + date_cut + '.html'\n",
    "\n",
    "# job()\n",
    "\n",
    "# # try:\n",
    "# #     job()\n",
    "# # except Exception:\n",
    "# #     pass \n",
    "\n",
    "# execTime = time.time()\n",
    "# print(\"The script took {0} seconds to complete...\".format(time.time() - execTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request HTA Map tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HTA Tiles of the alerted Area (wld_grid_100ka1_wfp) @ 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.read(os.path.join(root, \"config.txt\"))\n",
    "# dbserver_hta = config.get('hta','dbserver_hta')\n",
    "# dbname_hta = config.get('hta','dbname_hta')\n",
    "# dbuser_hta = config.get('hta','dbuser_hta')\n",
    "# dbpword_hta = config.get('hta','dbpword_hta')\n",
    "# dbport_hta = config.get('hta','dbport_hta')\n",
    "# hta_engine = create_engine('postgresql+psycopg2://' + dbuser_hta + ':' + dbpword_hta + '@' + dbserver_hta + ':' + dbport_hta + '/' + dbname_hta)\n",
    "# conn3 = hta_engine.raw_connection()\n",
    "# cur3 = conn3.cursor()\n",
    "# sql = \"\"\"  SELECT adm0_name,iso3,map_code,map_done,url,shape as geometry\n",
    "#          FROM wfp_pub.wfp.wld_grid_100ka1_wfp where map_done = 'yes'  \"\"\"\n",
    "# remote_df = gpd.GeoDataFrame.from_postgis(sql,conn3,geom_col='geometry')\n",
    "# conn3.close()\n",
    "\n",
    "# # import folium\n",
    "# # m = folium.Map(tiles='cartodbdark_matter') #cartodbpositron #stamentoner #cartodbdark_matter\n",
    "# # folium.GeoJson(remote_df).add_to(m)\n",
    "# # m.fit_bounds(m.get_bounds())\n",
    "# # m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn3 = hta_engine.raw_connection()\n",
    "# cur3 = conn3.cursor()\n",
    "# hta_sql = \"\"\"  SELECT adm0_name,iso3,map_code,map_done,url,shape as geometry\n",
    "#           FROM wfp_pub.wfp.wld_grid_100ka1_wfp where map_done != 'yes'  \"\"\"\n",
    "# remote_hta_gdf = gpd.GeoDataFrame.from_postgis(hta_sql,conn3,geom_col='geometry')\n",
    "# request_hta = gpd.overlay(remote_hta_gdf, alert, how='intersection')\n",
    "# #conn3.close()\n",
    "\n",
    "# config.read(os.path.join(root, \"config.txt\"))\n",
    "# dbserver_hta = config.get('hta','dbserver_hta')\n",
    "# dbname_hta = config.get('hta','dbname_hta')\n",
    "# dbuser_hta = config.get('hta','dbuser_hta')\n",
    "# dbpword_hta = config.get('hta','dbpword_hta')\n",
    "# dbport_hta = config.get('hta','dbport_hta')\n",
    "# hta_engine = create_engine('postgresql+psycopg2://' + dbuser_hta + ':' + dbpword_hta + '@' + dbserver_hta + ':' + dbport_hta + '/' + dbname_hta)\n",
    "# conn3 = hta_engine.raw_connection()\n",
    "# cur3 = conn3.cursor()\n",
    "# sql = \"\"\"  SELECT adm0_name,iso3,map_code,map_done,url,shape as geometry\n",
    "#          FROM wfp_pub.wfp.wld_grid_100ka1_wfp where map_done = 'yes'  \"\"\"\n",
    "# remote_df = gpd.GeoDataFrame.from_postgis(sql,conn3,geom_col='geometry')\n",
    "# conn3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Optional Plot ECMWF raster forecast\n",
    "# raster = rasterio.open(ecmwf_F_3D)\n",
    "# array = raster.read()\n",
    "# from IPython.display import Image\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "# show(array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECMWF Local Compute Processing - Work In Progress (xarray/dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_file = '/Users/michael/GEO/process_cdsapi/'\n",
    "\n",
    "# c = cdsapi.Client()\n",
    "\n",
    "# c.retrieve(\n",
    "#     'reanalysis-era5-single-levels-monthly-means',\n",
    "#     {\n",
    "#         'format':'netcdf',\n",
    "#         'product_type':'monthly_averaged_reanalysis',\n",
    "#         'variable':'total_precipitation',\n",
    "#         'year':[\n",
    "#             '1979','1980','1981',\n",
    "#             '1982','1983','1984',\n",
    "#             '1985','1986','1987',\n",
    "#             '1988','1989','1990',\n",
    "#             '1991','1992','1993',\n",
    "#             '1994','1995','1996',\n",
    "#             '1997','1998','1999',\n",
    "#             '2000','2001','2002',\n",
    "#             '2003','2004','2005',\n",
    "#             '2006','2007','2008',\n",
    "#             '2009','2010','2011',\n",
    "#             '2012','2013','2014',\n",
    "#             '2015','2016','2017',\n",
    "#             '2018'\n",
    "#         ],\n",
    "#         'month':[\n",
    "#             '01','02','03',\n",
    "#             '04','05','06',\n",
    "#             '07','08','09',\n",
    "#             '10','11','12'\n",
    "#         ],\n",
    "#         'time':'00:00'\n",
    "#     },\n",
    "#     outfile + 'monthly_average_reanalysis.nc')\n",
    "\n",
    "# tot_precip = '/Users/michael/GEO/process_cdsapi/total_precip.tif'\n",
    "# cdsapi_stats = zonal_stats(alert, tot_precip, prefix='cds_x',geojson_out=True)\n",
    "# zonal_ppt_gdf = GeoDataFrame.from_features(cdsapi_stats)\n",
    "\n",
    "### Reference: https://github.com/jwagemann/seasonal_forecasts/blob/master/Workflow_seasonal_fc_processing.ipynb\n",
    "### Reference: https://annefou.github.io/metos_python/07-LargeFiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WorldClim V1\n",
    "#worldclim = ee.ImageCollection('WORLDCLIM/V1/MONTHLY')\n",
    "#precip = worldclim.select('prec')\n",
    "#collectionList = precip.toList(precip.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hxl \n",
    "#source = hxl.data('http://wfp.org/dataset.xlsx')\n",
    "#from hdx.location.country import Country\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
